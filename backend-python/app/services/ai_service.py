import openai
import anthropic
import markdown
import json
import re
from typing import List, Dict, Any, Optional, Literal, Tuple
from sqlalchemy.orm import Session
from difflib import SequenceMatcher

from ..models import User, Agent, Article
from ..utils.security import decrypt
from ..utils.exceptions import OpenAIKeyError, ValidationError
from ..models_config import get_model_for_provider, get_model_info
from .unified_ai import UnifiedAIClient


TaskType = Literal["rewrite", "continue", "custom"]


class AIService:
    
    @staticmethod
    def _classify_task_type(user_input: str, context: Optional[str] = None) -> TaskType:
        """åˆ†ç±»ä»»åŠ¡ç±»å‹"""
        rewrite_keywords = ["ä¿®æ”¹", "æ”¹å†™", "ä¼˜åŒ–", "æ¶¦è‰²", "æ”¹è¿›", "è°ƒæ•´", "é‡å†™", "ç¼–è¾‘"]
        continue_keywords = ["ç»§ç»­", "ç»­å†™", "è¡¥å……", "æ‰©å±•", "æ¥ç€å†™", "æ·»åŠ ", "å»¶ä¼¸"]
        
        input_lower = user_input.lower()
        
        # æ£€æŸ¥æ”¹å†™å…³é”®è¯
        for keyword in rewrite_keywords:
            if keyword in user_input:
                return "rewrite"
        
        # æ£€æŸ¥ç»­å†™å…³é”®è¯
        for keyword in continue_keywords:
            if keyword in user_input:
                return "continue"
        
        # é»˜è®¤ä¸ºè‡ªå®šä¹‰ä»»åŠ¡
        return "custom"
    
    @staticmethod
    def _extract_changes(original: str, modified: str) -> List[Dict[str, Any]]:
        """æå–æ–‡æœ¬ä¿®æ”¹è¯¦æƒ…"""
        changes = []
        matcher = SequenceMatcher(None, original, modified)
        
        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'replace':
                changes.append({
                    "type": "modify",
                    "original": original[i1:i2],
                    "modified": modified[j1:j2],
                    "position": {"start": i1, "end": i2}
                })
            elif tag == 'delete':
                changes.append({
                    "type": "delete",
                    "original": original[i1:i2],
                    "modified": "",
                    "position": {"start": i1, "end": i2}
                })
            elif tag == 'insert':
                changes.append({
                    "type": "add",
                    "original": "",
                    "modified": modified[j1:j2],
                    "position": {"start": i1, "end": i1}
                })
        
        return changes
    
    @staticmethod
    def _get_openai_client(user: User) -> openai.OpenAI:
        """è·å–OpenAIå®¢æˆ·ç«¯"""
        if not user.openaiKey:
            raise OpenAIKeyError("OpenAI API Key not configured")

        try:
            api_key = decrypt(user.openaiKey)
            return openai.OpenAI(api_key=api_key)
        except Exception as e:
            raise OpenAIKeyError("Failed to decrypt OpenAI API Key")

    @staticmethod
    def _get_claude_client(user: User) -> anthropic.Anthropic:
        """è·å–Claudeå®¢æˆ·ç«¯"""
        if not user.claudeKey:
            raise ValidationError("Claude API Key not configured")

        try:
            api_key = decrypt(user.claudeKey)
            return anthropic.Anthropic(api_key=api_key)
        except Exception as e:
            raise ValidationError("Failed to decrypt Claude API Key")

    @staticmethod
    def _determine_provider(user: User, preferred_provider: str = None) -> str:
        """
        ç¡®å®šä½¿ç”¨å“ªä¸ªAIæä¾›å•†

        Args:
            user: ç”¨æˆ·å¯¹è±¡
            preferred_provider: åå¥½çš„æä¾›å•† (openai, claude, gemini)

        Returns:
            å¯ç”¨çš„æä¾›å•†åç§°
        """
        # å¦‚æœæŒ‡å®šäº†åå¥½æä¾›å•†ä¸”è¯¥æä¾›å•†å¯ç”¨
        if preferred_provider:
            if preferred_provider == "openai" and user.openaiKey:
                return "openai"
            elif preferred_provider == "claude" and user.claudeKey:
                return "claude"
            elif preferred_provider == "gemini" and user.geminiKey:
                return "gemini"

        # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥å¯ç”¨çš„æä¾›å•†
        if user.openaiKey:
            return "openai"
        elif user.claudeKey:
            return "claude"
        elif user.geminiKey:
            return "gemini"
        else:
            raise ValidationError("No AI API keys configured")
    
    @classmethod
    async def _call_ai(
        cls,
        user: User,
        messages: List[Dict[str, str]],
        provider: str = None,
        model: str = None,
        temperature: float = 0.7,
        max_tokens: int = 2000
    ) -> str:
        """
        ç»Ÿä¸€çš„AIè°ƒç”¨æ¥å£ï¼Œæ”¯æŒå¤šä¸ªæä¾›å•†

        ä½¿ç”¨UnifiedAIClientè‡ªåŠ¨å¤„ç†ä¸åŒæä¾›å•†çš„æ¶ˆæ¯æ ¼å¼å’ŒAPIå·®å¼‚

        Args:
            user: ç”¨æˆ·å¯¹è±¡
            messages: æ¶ˆæ¯åˆ—è¡¨
            provider: AIæä¾›å•† (openai, claude, gemini)
            model: æŒ‡å®šçš„æ¨¡å‹ID
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°

        Returns:
            AIå“åº”æ–‡æœ¬
        """
        # DEBUG: æ£€æŸ¥providerå‚æ•°
        print(f"ğŸ” AIService._call_ai: provider={provider}, model={model}, temperature={temperature}")

        # ä½¿ç”¨ç»Ÿä¸€çš„AIå®¢æˆ·ç«¯
        return await UnifiedAIClient.call(
            user=user,
            messages=messages,
            provider=provider,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens
        )

    @staticmethod
    def _build_system_prompt(agent: Agent) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        tone_map = {
            "professional": "ä¸“ä¸šä¸¥è°¨",
            "casual": "è½»æ¾éšæ„", 
            "humorous": "å¹½é»˜é£è¶£",
            "serious": "ä¸¥è‚ƒè®¤çœŸ"
        }
        
        length_map = {
            "short": "ç®€æ´ç²¾ç‚¼ï¼Œæ§åˆ¶åœ¨500å­—ä»¥å†…",
            "medium": "é€‚ä¸­è¯¦ç»†ï¼Œæ§åˆ¶åœ¨500-1500å­—",
            "long": "è¯¦ç»†å……åˆ†ï¼Œ1500å­—ä»¥ä¸Š"
        }
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ª{agent.name}ï¼Œä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ç´ æç”Ÿæˆé«˜è´¨é‡çš„åšå®¢æ–‡ç« ã€‚

ä½ çš„å†™ä½œç‰¹ç‚¹ï¼š
- è¯­è¨€ï¼š{agent.language if agent.language == 'zh-CN' else 'è‹±æ–‡' if agent.language == 'en-US' else 'ä¸­è‹±æ··åˆ'}
- è¯­æ°”ï¼š{tone_map.get(agent.tone, agent.tone)}
- ç¯‡å¹…ï¼š{length_map.get(agent.lengthPreference, agent.lengthPreference)}"""

        if agent.targetAudience:
            prompt += f"\n- ç›®æ ‡è¯»è€…ï¼š{agent.targetAudience}"
        
        if agent.description:
            prompt += f"\n- ç‰¹ç‚¹æè¿°ï¼š{agent.description}"
        
        if agent.customPrompt:
            prompt += f"\n\nç‰¹æ®Šè¦æ±‚ï¼š{agent.customPrompt}"
        
        prompt += f"""

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
1. æ–‡ç« å¿…é¡»æ˜¯Markdownæ ¼å¼ï¼ˆæˆ‘ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºHTMLï¼‰
2. åŒ…å«é€‚å½“çš„æ ‡é¢˜å±‚çº§ï¼ˆä½¿ç”¨ #, ##, ### ç­‰ï¼‰
3. å¦‚æœé€‚åˆï¼Œå¯ä»¥åŒ…å«ä»£ç å—ã€åˆ—è¡¨ã€å¼•ç”¨ç­‰å…ƒç´ 
4. æ–‡ç« ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘æµç•…
5. ä½¿ç”¨æ ‡å‡†Markdownè¯­æ³•ï¼Œç¡®ä¿è½¬æ¢ä¸ºHTMLåæ ¼å¼æ­£ç¡®

è¯·ç›´æ¥è¾“å‡ºæ–‡ç« å†…å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜ã€‚"""
        
        return prompt
    
    @staticmethod
    def _build_chat_system_prompt(agent: Agent, materials: Optional[str] = None) -> str:
        """æ„å»ºå¯¹è¯ç³»ç»Ÿæç¤ºè¯"""
        tone_map = {
            "professional": "ä¸“ä¸šä¸¥è°¨",
            "casual": "è½»æ¾éšæ„",
            "humorous": "å¹½é»˜é£è¶£", 
            "serious": "ä¸¥è‚ƒè®¤çœŸ"
        }
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ª{agent.name}ï¼Œæ­£åœ¨å’Œç”¨æˆ·è¿›è¡Œå¯¹è¯ï¼Œå¸®åŠ©ç”¨æˆ·ç”Ÿæˆåšå®¢æ–‡ç« ã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
- è¯­è¨€ï¼š{agent.language if agent.language == 'zh-CN' else 'è‹±æ–‡' if agent.language == 'en-US' else 'ä¸­è‹±æ··åˆ'}
- è¯­æ°”ï¼š{tone_map.get(agent.tone, agent.tone)}"""

        if agent.targetAudience:
            prompt += f"\n- ç›®æ ‡è¯»è€…ï¼š{agent.targetAudience}"
        
        if agent.description:
            prompt += f"\n- ç‰¹ç‚¹æè¿°ï¼š{agent.description}"
        
        if materials:
            prompt += f"\n\nå‚è€ƒç´ æï¼š\n{materials}"
            prompt += "\n\nä½ å¯ä»¥åœ¨å¯¹è¯ä¸­å¼•ç”¨è¿™äº›ç´ æï¼Œå›ç­”ç”¨æˆ·å…³äºç´ æçš„é—®é¢˜ï¼Œæˆ–è€…åŸºäºç´ ææä¾›å»ºè®®ã€‚"
        
        prompt += """

è¯·ä»¥å‹å¥½ã€æœ‰å¸®åŠ©çš„æ–¹å¼ä¸ç”¨æˆ·å¯¹è¯ã€‚ä½ å¯ä»¥ï¼š
1. å›ç­”ç”¨æˆ·å…³äºå†™ä½œçš„é—®é¢˜
2. åŸºäºç´ ææä¾›å†™ä½œå»ºè®®
3. å¸®åŠ©ç”¨æˆ·æ¢³ç†æ–‡ç« ç»“æ„
4. æä¾›å†…å®¹ä¼˜åŒ–å»ºè®®
5. ä¸ç”¨æˆ·è®¨è®ºæ–‡ç« ä¸»é¢˜å’Œæ–¹å‘

ä¿æŒå¯¹è¯è‡ªç„¶æµç•…ï¼Œä¸è¦å¤ªè¿‡å†—é•¿ã€‚"""
        
        return prompt
    
    @staticmethod
    def _markdown_to_html(markdown_text: str) -> str:
        """å°†Markdownè½¬æ¢ä¸ºHTML"""
        # é…ç½®markdownæ‰©å±•
        md = markdown.Markdown(extensions=[
            'extra',  # åŒ…æ‹¬è¡¨æ ¼ã€ä»£ç å—ç­‰
            'codehilite',  # ä»£ç é«˜äº®
            'fenced_code',  # å›´æ ä»£ç å—
            'tables',  # è¡¨æ ¼æ”¯æŒ
            'toc',  # ç›®å½•æ”¯æŒ
            'nl2br',  # æ¢è¡Œè½¬<br>
            'sane_lists',  # æ›´å¥½çš„åˆ—è¡¨å¤„ç†
        ])
        return md.convert(markdown_text)
    
    @staticmethod
    def _parse_article_response(response: str, provided_title: Optional[str] = None) -> Dict[str, str]:
        """è§£ææ–‡ç« ç”Ÿæˆå“åº”"""
        lines = response.strip().split('\n')
        title = provided_title or "æœªå‘½åæ–‡ç« "
        markdown_content = response
        
        # å¦‚æœå“åº”ä»¥ # å¼€å¤´ï¼Œè¯´æ˜åŒ…å«äº†æ ‡é¢˜
        if lines and lines[0].startswith('# '):
            title = lines[0].replace('# ', '').strip()
            markdown_content = '\n'.join(lines[1:]).strip()
        
        # å°†Markdownè½¬æ¢ä¸ºHTML
        html_content = AIService._markdown_to_html(markdown_content)
        
        # ç”Ÿæˆæ‘˜è¦ï¼ˆå–å‰200ä¸ªå­—ç¬¦ï¼‰
        plain_text = markdown_content.replace('#', '').replace('*', '').replace('`', '').strip()
        summary = plain_text[:200] + '...' if len(plain_text) > 200 else plain_text
        
        return {
            "title": title,
            "content": html_content,  # è¿”å›HTMLå†…å®¹
            "summary": summary,
            "markdown_content": markdown_content  # ä¿ç•™åŸå§‹Markdownå†…å®¹ä»¥å¤‡éœ€è¦
        }
    
    @classmethod
    async def generate_article(
        cls,
        user: User,
        agent: Agent,
        materials: str,
        title: Optional[str] = None,
        requirements: Optional[str] = None
    ) -> Dict[str, str]:
        """ç”Ÿæˆæ–‡ç« """
        
        client = cls._get_openai_client(user)
        system_prompt = cls._build_system_prompt(agent)
        
        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = "è¯·æ ¹æ®ä»¥ä¸‹ç´ æç”Ÿæˆä¸€ç¯‡åšå®¢æ–‡ç« ï¼š\n\n"
        
        if title:
            user_prompt += f"æ–‡ç« æ ‡é¢˜ï¼š{title}\n\n"
        
        user_prompt += f"ç´ æå†…å®¹ï¼š\n{materials}\n\n"
        
        if requirements:
            user_prompt += f"é¢å¤–è¦æ±‚ï¼š{requirements}\n\n"
        
        if not title:
            user_prompt += "è¯·ä¸ºæ–‡ç« ç”Ÿæˆä¸€ä¸ªåˆé€‚çš„æ ‡é¢˜ã€‚\n"
        
        try:
            response = client.chat.completions.create(
                model=get_model_for_provider("openai"),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )
            
            generated_content = response.choices[0].message.content or ""
            return cls._parse_article_response(generated_content, title)
            
        except Exception as e:
            raise ValidationError(f"AI generation failed: {str(e)}")
    
    @classmethod
    async def generate_chat_response(
        cls,
        user: User,
        agent: Agent,
        messages: List[Dict[str, str]],
        materials: Optional[str] = None
    ) -> str:
        """ç”Ÿæˆå¯¹è¯å“åº”"""
        
        client = cls._get_openai_client(user)
        system_prompt = cls._build_chat_system_prompt(agent, materials)
        
        # æ„å»ºå¯¹è¯æ¶ˆæ¯
        chat_messages = [{"role": "system", "content": system_prompt}]
        chat_messages.extend([
            {"role": msg["role"], "content": msg["content"]} 
            for msg in messages
        ])
        
        try:
            response = client.chat.completions.create(
                model=get_model_for_provider("openai"),
                messages=chat_messages,
                temperature=0.7,
                max_tokens=1000
            )
            
            return response.choices[0].message.content or "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚"
            
        except Exception as e:
            raise ValidationError(f"Chat generation failed: {str(e)}")
    
    @classmethod
    async def improve_article(
        cls,
        user: User, 
        agent: Agent,
        current_content: str,
        instructions: str
    ) -> str:
        """æ”¹è¿›æ–‡ç« """
        
        client = cls._get_openai_client(user)
        system_prompt = cls._build_system_prompt(agent)
        
        user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æŒ‡ç¤ºæ”¹è¿›è¿™ç¯‡æ–‡ç« ï¼š

å½“å‰æ–‡ç« å†…å®¹ï¼š
{current_content}

æ”¹è¿›è¦æ±‚ï¼š
{instructions}

è¯·ç›´æ¥è¾“å‡ºæ”¹è¿›åçš„å®Œæ•´æ–‡ç« å†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰ã€‚"""
        
        try:
            response = client.chat.completions.create(
                model=get_model_for_provider("openai"),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )
            
            markdown_response = response.choices[0].message.content or current_content
            # å°†Markdownè½¬æ¢ä¸ºHTML
            return cls._markdown_to_html(markdown_response)
            
        except Exception as e:
            raise ValidationError(f"Article improvement failed: {str(e)}")
    
    @classmethod
    async def analyze_writing_style(
        cls,
        user: User,
        content: str,
        content_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """åˆ†ææ–‡æœ¬å†…å®¹å¹¶ç”Ÿæˆå†™ä½œé£æ ¼æè¿°"""
        
        client = cls._get_openai_client(user)
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œé£æ ¼åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. åˆ¤æ–­å†…å®¹ç±»å‹ï¼ˆå¯¹è¯è®°å½•æˆ–æ–‡ç« ï¼‰
2. åˆ†æå†™ä½œé£æ ¼ç‰¹å¾
3. ç”Ÿæˆä¸€ä¸ªé€‚åˆä½œä¸ºAI Agent customPromptçš„é£æ ¼æè¿°

è¯·åˆ†æä»¥ä¸‹å‡ ä¸ªç»´åº¦ï¼š
- è¯­è¨€é£æ ¼ï¼ˆæ­£å¼/éæ­£å¼ã€ä¸“ä¸š/é€šä¿—ç­‰ï¼‰
- å¥å¼ç‰¹ç‚¹ï¼ˆé•¿çŸ­ã€å¤æ‚åº¦ï¼‰
- ç”¨è¯ä¹ æƒ¯ï¼ˆä¸“ä¸šæœ¯è¯­ã€å£è¯­åŒ–ç¨‹åº¦ï¼‰
- è¡¨è¾¾æ–¹å¼ï¼ˆç›´æ¥/å§”å©‰ã€ç†æ€§/æ„Ÿæ€§ï¼‰
- ç‰¹æ®Šä¹ æƒ¯ï¼ˆæ ‡ç‚¹ä½¿ç”¨ã€æ®µè½ç»„ç»‡ç­‰ï¼‰

è¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«ï¼š
{
    "detectedType": "conversation" æˆ– "article",
    "styleDescription": "ä¸€æ®µå®Œæ•´çš„é£æ ¼æè¿°ï¼Œå¯ç›´æ¥ç”¨ä½œcustomPrompt",
    "characteristics": {
        "language": "è¯­è¨€ç‰¹ç‚¹",
        "tone": "è¯­æ°”é£æ ¼",
        "sentenceStyle": "å¥å¼ç‰¹ç‚¹",
        "vocabulary": "ç”¨è¯ç‰¹å¾",
        "specialTraits": "ç‰¹æ®Šä¹ æƒ¯"
    }
}"""
        
        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = f"è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„å†™ä½œé£æ ¼ï¼š\n\n{content[:3000]}"  # é™åˆ¶é•¿åº¦é¿å…è¶…å‡ºtokené™åˆ¶
        
        if content_type:
            user_prompt = f"å†…å®¹ç±»å‹æç¤ºï¼š{content_type}\n\n" + user_prompt
        
        try:
            response = client.chat.completions.create(
                model=get_model_for_provider("openai"),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„åˆ†æç»“æœ
                max_tokens=1000,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content or "{}")
            
            # ç¡®ä¿è¿”å›æ ¼å¼æ­£ç¡®
            if not all(key in result for key in ["detectedType", "styleDescription", "characteristics"]):
                raise ValidationError("Invalid response format from AI")
            
            return result
            
        except json.JSONDecodeError:
            raise ValidationError("Failed to parse AI response as JSON")
        except Exception as e:
            raise ValidationError(f"Writing style analysis failed: {str(e)}")
    
    @classmethod
    async def generate_structured_response(
        cls,
        user: User,
        agent: Agent,
        user_input: str,
        context: Optional[str] = None,
        task_type: Optional[TaskType] = None,
        original_content: Optional[str] = None
    ) -> Dict[str, Any]:
        """ç”Ÿæˆç»“æ„åŒ–çš„JSONå“åº”"""
        
        client = cls._get_openai_client(user)
        
        # è‡ªåŠ¨åˆ†ç±»ä»»åŠ¡ç±»å‹ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if not task_type:
            task_type = cls._classify_task_type(user_input, context)
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ„å»ºç³»ç»Ÿæç¤ºè¯
        base_system_prompt = cls._build_system_prompt(agent)
        
        # æ·»åŠ JSONæ ¼å¼åŒ–è¦æ±‚
        json_format_prompt = f"""
{base_system_prompt}

é‡è¦ï¼šä½ å¿…é¡»è¿”å›ä¸€ä¸ªä¸¥æ ¼çš„JSONæ ¼å¼å“åº”ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
    "type": "{task_type}",
    "result": "å¤„ç†åçš„æ–‡æœ¬å†…å®¹",
    "metadata": {{
        "confidence": 0.95,  // ä»»åŠ¡ç±»å‹åˆ¤æ–­ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
        "suggestions": []    // å¯é€‰çš„é¢å¤–å»ºè®®
    }}
}}
"""
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹å®šåˆ¶æç¤ºè¯
        if task_type == "rewrite":
            json_format_prompt += """
å¯¹äºæ”¹å†™ä»»åŠ¡ï¼Œmetadataä¸­è¿˜éœ€è¦åŒ…å«ï¼š
- "original": "åŸå§‹æ–‡æœ¬"
- "changes": [ä¿®æ”¹è¯¦æƒ…æ•°ç»„]
"""
            user_prompt = f"""ä»»åŠ¡ç±»å‹ï¼šæ”¹å†™/ä¼˜åŒ–æ–‡æœ¬
ç”¨æˆ·æŒ‡ä»¤ï¼š{user_input}

éœ€è¦æ”¹å†™çš„æ–‡æœ¬ï¼š
{original_content or context}

è¯·æŒ‰ç…§JSONæ ¼å¼è¿”å›æ”¹å†™ç»“æœã€‚"""
        
        elif task_type == "continue":
            user_prompt = f"""ä»»åŠ¡ç±»å‹ï¼šç»­å†™æ–‡æœ¬
ç”¨æˆ·æŒ‡ä»¤ï¼š{user_input}

å·²æœ‰æ–‡æœ¬ï¼š
{context}

è¯·æŒ‰ç…§JSONæ ¼å¼è¿”å›ç»­å†™å†…å®¹ã€‚"""
        
        else:  # custom
            user_prompt = f"""ä»»åŠ¡ç±»å‹ï¼šè‡ªå®šä¹‰å¤„ç†
ç”¨æˆ·æŒ‡ä»¤ï¼š{user_input}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

è¯·æŒ‰ç…§JSONæ ¼å¼è¿”å›å¤„ç†ç»“æœã€‚"""
        
        try:
            response = client.chat.completions.create(
                model=get_model_for_provider("openai"),
                messages=[
                    {"role": "system", "content": json_format_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=4000,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content or "{}")
            
            # å¦‚æœæ˜¯æ”¹å†™ä»»åŠ¡ï¼Œè®¡ç®—æ–‡æœ¬å·®å¼‚
            if task_type == "rewrite" and original_content:
                if "metadata" not in result:
                    result["metadata"] = {}
                
                result["metadata"]["original"] = original_content
                result["metadata"]["changes"] = cls._extract_changes(
                    original_content, 
                    result.get("result", "")
                )
            
            return result
            
        except json.JSONDecodeError:
            raise ValidationError("Failed to parse AI response as JSON")
        except Exception as e:
            raise ValidationError(f"Structured response generation failed: {str(e)}")
    
    @classmethod
    async def process_text_with_structure(
        cls,
        user: User,
        agent: Agent,
        input_text: str,
        context: Optional[str] = None,
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """å¤„ç†æ–‡æœ¬å¹¶è¿”å›ç»“æ„åŒ–å“åº”ï¼ˆç»Ÿä¸€APIï¼‰"""
        
        options = options or {}
        task_type = options.get("task_type")
        
        # å¦‚æœæ˜¯æ”¹å†™ä»»åŠ¡ï¼Œéœ€è¦åŸæ–‡
        original_content = None
        if task_type == "rewrite" or cls._classify_task_type(input_text) == "rewrite":
            original_content = context
        
        return await cls.generate_structured_response(
            user=user,
            agent=agent,
            user_input=input_text,
            context=context,
            task_type=task_type,
            original_content=original_content
        )

    @classmethod
    async def perform_text_action(
        cls,
        user: User,
        agent: Agent,
        text: str,
        action_type: str,
        context: Optional[str] = None,
        language: Optional[str] = None,
        provider: str = None,
        model: str = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œæ–‡æœ¬æ“ä½œï¼ˆæ”¹è¿›ã€è§£é‡Šã€æ‰©å±•ç­‰ï¼‰"""

        system_prompt = cls._build_system_prompt(agent)

        # æ ¹æ®æ“ä½œç±»å‹æ„å»ºä¸åŒçš„æç¤ºè¯
        action_prompts = {
            "improve": "è¯·æ”¹è¿›ä»¥ä¸‹æ–‡æœ¬ï¼Œä½¿å…¶æ›´åŠ æ¸…æ™°ã€å‡†ç¡®å’Œæœ‰è¯´æœåŠ›ï¼Œä¿æŒåŸæ„ä¸å˜ï¼š",
            "explain": "è¯·è¯¦ç»†è§£é‡Šä»¥ä¸‹æ–‡æœ¬çš„å«ä¹‰ã€èƒŒæ™¯å’Œé‡è¦æ¦‚å¿µï¼š",
            "expand": "è¯·æ‰©å±•ä»¥ä¸‹æ–‡æœ¬ï¼Œæ·»åŠ æ›´å¤šç»†èŠ‚ã€ä¾‹å­å’Œç›¸å…³ä¿¡æ¯ï¼š",
            "summarize": "è¯·æ€»ç»“ä»¥ä¸‹æ–‡æœ¬çš„å…³é”®è¦ç‚¹å’Œä¸»è¦å†…å®¹ï¼š",
            "translate": f"è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆ{language or 'è‹±æ–‡'}ï¼š",
            "rewrite": "è¯·ç”¨ä¸åŒçš„è¡¨è¾¾æ–¹å¼é‡å†™ä»¥ä¸‹æ–‡æœ¬ï¼Œä¿æŒæ ¸å¿ƒæ„æ€ä¸å˜ï¼š"
        }

        action_prompt = action_prompts.get(action_type, "è¯·å¤„ç†ä»¥ä¸‹æ–‡æœ¬ï¼š")

        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = f"{action_prompt}\n\næ–‡æœ¬å†…å®¹ï¼š\n{text}"

        if context:
            user_prompt += f"\n\nä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š\n{context}"

        if action_type in ["improve", "rewrite"]:
            user_prompt += "\n\nè¯·æä¾›ç®€è¦çš„ä¿®æ”¹è¯´æ˜ã€‚"

        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„AIè°ƒç”¨æ–¹æ³•
            processed_text = await cls._call_ai(
                user=user,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                provider=provider,
                model=model,
                temperature=0.7,
                max_tokens=2000
            )

            # å¯¹äºæ”¹è¿›å’Œé‡å†™æ“ä½œï¼Œå°è¯•åˆ†ç¦»ç»“æœå’Œè¯´æ˜
            explanation = None
            if action_type in ["improve", "rewrite"]:
                # å°è¯•å¤šç§åˆ†éš”ç¬¦
                separators = ["ä¿®æ”¹è¯´æ˜ï¼š", "ä¿®æ”¹è¯´æ˜:", "è¯´æ˜ï¼š", "è¯´æ˜:", "\n\nä¿®æ”¹è¯´æ˜", "\nä¿®æ”¹è¯´æ˜"]
                for sep in separators:
                    if sep in processed_text:
                        parts = processed_text.split(sep, 1)  # åªåˆ†å‰²ç¬¬ä¸€æ¬¡å‡ºç°
                        if len(parts) == 2:
                            processed_text = parts[0].strip()
                            explanation = parts[1].strip()
                            break

            return {
                "actionType": action_type,
                "originalText": text,
                "processedText": processed_text,
                "explanation": explanation
            }

        except Exception as e:
            raise ValidationError(f"Text action failed: {str(e)}")