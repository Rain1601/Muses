from fastapi import APIRouter, UploadFile, File, HTTPException, Depends
from typing import List, Optional
import tempfile
import os
import shutil
import zipfile
import re
import base64
import logging
from pathlib import Path

from ..dependencies import get_current_user_db
from ..models.user import User
from ..models.article import Article
from ..database import SessionLocal
from ..utils.security import decrypt
import httpx

logger = logging.getLogger(__name__)
router = APIRouter()

@router.post("/upload-files")
async def upload_files(
    files: List[UploadFile] = File(...),
    current_user: User = Depends(get_current_user_db)
):
    """ä¸Šä¼ æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è¿›è¡Œå¯¼å…¥"""
    try:
        logger.info(f"ğŸ“ Starting file upload for user: {current_user.username}")
        logger.info(f"ğŸ“Š Uploaded {len(files)} files")

        # è¯¦ç»†è®°å½•æ¯ä¸ªæ–‡ä»¶çš„ä¿¡æ¯
        for i, file in enumerate(files):
            logger.info(f"ğŸ“„ File {i+1}: {file.filename} (size: {file.size if hasattr(file, 'size') else 'unknown'}, type: {file.content_type})")
            if hasattr(file, 'size') and file.size == 0:
                logger.warning(f"âš ï¸ Empty file detected: {file.filename}")
            if not file.filename or file.filename == '':
                logger.warning(f"âš ï¸ Empty filename detected")

        # è¿‡æ»¤æ‰ç©ºæ–‡ä»¶å’Œæ— æ•ˆæ–‡ä»¶
        valid_files = []
        for file in files:
            # æ£€æŸ¥æ–‡ä»¶åå’Œå¤§å°
            if (file.filename and
                file.filename.strip() and
                not file.filename.endswith('/') and
                not file.filename.endswith('.DS_Store') and
                file.filename != '.DS_Store'):

                # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if hasattr(file, 'size') and file.size == 0:
                    logger.warning(f"âš ï¸ Skipping empty file: {file.filename}")
                    continue

                valid_files.append(file)
                logger.info(f"âœ… Valid file added: {file.filename}")
            else:
                logger.warning(f"âš ï¸ Skipping invalid file: {file.filename}")

        logger.info(f"âœ… Valid files: {len(valid_files)}/{len(files)}")

        if len(valid_files) == 0:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ–‡ä»¶ã€‚è¯·ç¡®ä¿é€‰æ‹©äº†åŒ…å« Markdown æ–‡ä»¶çš„æ–‡ä»¶å¤¹ï¼Œå¹¶æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©ºã€‚")

        files = valid_files

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
            markdown_files = []
            image_files = {}

            for file in files:
                file_path = temp_path / file.filename

                # åˆ›å»ºå¿…è¦çš„ç›®å½•
                file_path.parent.mkdir(parents=True, exist_ok=True)

                # ä¿å­˜æ–‡ä»¶
                content = await file.read()
                with open(file_path, 'wb') as f:
                    f.write(content)

                logger.info(f"ğŸ“„ Saved file: {file.filename}")

                # åˆ†ç±»æ–‡ä»¶
                if file.filename.endswith('.md'):
                    markdown_files.append(file_path)
                elif any(file.filename.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.gif', '.svg']):
                    # æå–ç›¸å¯¹è·¯å¾„ä½œä¸ºé”®ï¼ŒåŒæ—¶ä¿å­˜å®Œæ•´è·¯å¾„å’Œæ–‡ä»¶å
                    rel_path = file.filename
                    filename_only = rel_path.split('/')[-1] if '/' in rel_path else rel_path

                    # ä¿å­˜å¤šç§å¯èƒ½çš„é”®å€¼æ˜ å°„
                    image_files[filename_only] = file_path  # åªæœ‰æ–‡ä»¶å
                    image_files[rel_path] = file_path       # å®Œæ•´ç›¸å¯¹è·¯å¾„

                    logger.info(f"ğŸ–¼ï¸ Registered image: {filename_only} -> {file_path}")

            logger.info(f"ğŸ“ Found {len(markdown_files)} markdown files")
            logger.info(f"ğŸ–¼ï¸ Found {len(image_files)} image files")

            # å¤„ç†æ¯ä¸ª Markdown æ–‡ä»¶
            imported_articles = []

            for md_file in markdown_files:
                try:
                    article_data = await process_markdown_file(md_file, image_files, current_user)
                    imported_articles.append(article_data)
                except Exception as e:
                    logger.error(f"âŒ Failed to process {md_file}: {str(e)}")
                    continue

            return {
                "success": True,
                "imported_count": len(imported_articles),
                "articles": imported_articles
            }

    except Exception as e:
        logger.error(f"âŒ File upload failed: {str(e)}")
        import traceback
        logger.error(f"Full traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")


async def process_markdown_file(md_file: Path, image_files: dict, current_user: User) -> dict:
    """å¤„ç†å•ä¸ª Markdown æ–‡ä»¶"""
    logger.info(f"ğŸ“– Processing markdown file: {md_file.name}")

    # è¯»å– Markdown å†…å®¹
    with open(md_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ª # æ ‡é¢˜ï¼‰
    title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
    title = title_match.group(1) if title_match else md_file.stem

    logger.info(f"ğŸ“‹ Article title: {title}")

    # ä¸Šä¼ å›¾ç‰‡å¹¶æ›¿æ¢é“¾æ¥
    processed_content = await process_images_in_markdown(content, image_files, current_user)

    # åœ¨è½¬æ¢å‰ä¿å­˜æ‰€æœ‰iframeæ ‡ç­¾
    iframe_placeholders = {}
    iframe_pattern = r'<iframe[^>]*>.*?</iframe>'

    def preserve_iframe(match):
        placeholder = f"__IFRAME_PLACEHOLDER_{len(iframe_placeholders)}__"
        iframe_placeholders[placeholder] = match.group(0)
        logger.info(f"ğŸ¬ Preserving iframe: {match.group(0)[:100]}...")
        return placeholder

    processed_content = re.sub(iframe_pattern, preserve_iframe, processed_content, flags=re.DOTALL)

    # å°†Markdownè½¬æ¢ä¸ºHTMLï¼ˆTipTapç¼–è¾‘å™¨éœ€è¦HTMLæ ¼å¼ï¼‰
    try:
        import markdown
        html_content = markdown.markdown(processed_content, extensions=[
            'markdown.extensions.tables',
            'markdown.extensions.fenced_code',
            'markdown.extensions.codehilite',
            'markdown.extensions.toc'
        ])
        processed_content = html_content
    except ImportError:
        # å¦‚æœæ²¡æœ‰markdownåº“ï¼Œä¿æŒåŸæ ¼å¼
        logger.warning("âš ï¸ Markdown library not found, saving as raw markdown")
        pass

    # æ¢å¤æ‰€æœ‰iframeæ ‡ç­¾
    for placeholder, iframe_html in iframe_placeholders.items():
        processed_content = processed_content.replace(placeholder, iframe_html)
        logger.info(f"âœ… Restored iframe from placeholder")

    # åˆ›å»ºæ–‡ç« è®°å½•
    db = SessionLocal()
    try:
        # è·å–ç”¨æˆ·çš„é»˜è®¤Agent
        from ..models.agent import Agent
        default_agent = db.query(Agent).filter(
            Agent.userId == current_user.id,
            Agent.isDefault == True
        ).first()

        if not default_agent:
            # å¦‚æœæ²¡æœ‰é»˜è®¤Agentï¼Œåˆ›å»ºä¸€ä¸ª
            default_agent = Agent(
                userId=current_user.id,
                name="å¯¼å…¥åŠ©æ‰‹",
                description="ç”¨äºå¯¼å…¥æ–‡ä»¶çš„é»˜è®¤åŠ©æ‰‹",
                language="chinese",
                tone="professional",
                lengthPreference="medium",
                targetAudience="general",
                isDefault=True
            )
            db.add(default_agent)
            db.flush()  # è·å–IDä½†ä¸æäº¤

        article = Article(
            title=title,
            content=processed_content,
            publishStatus="draft",
            userId=current_user.id,
            agentId=default_agent.id
        )

        db.add(article)
        db.commit()
        db.refresh(article)

        logger.info(f"âœ… Created article: {article.id}")

        return {
            "id": article.id,
            "title": article.title,
            "status": article.publishStatus,
            "created_at": article.createdAt.isoformat()
        }

    finally:
        db.close()


async def process_images_in_markdown(content: str, image_files: dict, current_user: User) -> str:
    """å¤„ç† Markdown ä¸­çš„å›¾ç‰‡é“¾æ¥"""
    logger.info(f"ğŸ–¼ï¸ Processing images in markdown content")

    # åŒ¹é… ![](image/filename) æ ¼å¼çš„å›¾ç‰‡é“¾æ¥
    image_pattern = r'!\[([^\]]*)\]\(([^)]+)\)'

    async def replace_image(match):
        alt_text = match.group(1)
        image_path = match.group(2)

        # æå–æ–‡ä»¶åå’Œå®Œæ•´è·¯å¾„
        filename_only = image_path.split('/')[-1] if '/' in image_path else image_path
        full_path = image_path

        logger.info(f"ğŸ” Looking for image: {image_path} (filename: {filename_only})")

        # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶ï¼Œä¼˜å…ˆå°è¯•å®Œæ•´è·¯å¾„ï¼Œç„¶åå°è¯•æ–‡ä»¶å
        local_image_path = None
        if full_path in image_files:
            local_image_path = image_files[full_path]
            logger.info(f"ğŸ“ Found image by full path: {local_image_path}")
        elif filename_only in image_files:
            local_image_path = image_files[filename_only]
            logger.info(f"ğŸ“ Found image by filename: {local_image_path}")

        if local_image_path:
            try:
                # ä¸Šä¼ å›¾ç‰‡åˆ° GitHub
                github_url = await upload_image_to_github(local_image_path, current_user)
                logger.info(f"âœ… Uploaded image to GitHub: {github_url}")

                # è¿”å›æ–°çš„ Markdown é“¾æ¥
                return f"![{alt_text}]({github_url})"

            except Exception as e:
                logger.error(f"âŒ Failed to upload image {filename_only}: {str(e)}")
                # ä¿æŒåŸé“¾æ¥
                return match.group(0)
        else:
            logger.warning(f"âš ï¸ Image not found: {image_path} (tried both full path and filename)")
            # ä¿æŒåŸé“¾æ¥
            return match.group(0)

    # æ›¿æ¢æ‰€æœ‰å›¾ç‰‡é“¾æ¥
    import asyncio

    # æ”¶é›†æ‰€æœ‰åŒ¹é…é¡¹
    matches = list(re.finditer(image_pattern, content))

    # é€ä¸ªå¤„ç†æ›¿æ¢
    processed_content = content
    offset = 0

    for match in matches:
        start = match.start() + offset
        end = match.end() + offset

        replacement = await replace_image(match)

        # è®¡ç®—åç§»é‡å˜åŒ–
        offset += len(replacement) - len(match.group(0))

        # æ›¿æ¢å†…å®¹
        processed_content = processed_content[:start] + replacement + processed_content[end:]

    return processed_content


async def upload_image_to_github(image_path: Path, current_user: User) -> str:
    """ä¸Šä¼ å›¾ç‰‡åˆ° GitHub ä»“åº“"""
    logger.info(f"ğŸ“¤ Uploading image to GitHub: {image_path.name}")

    # æ£€æŸ¥ç”¨æˆ·çš„ GitHub é…ç½®
    if not current_user.githubToken or not current_user.defaultRepoUrl:
        raise Exception("GitHub é…ç½®ä¸å®Œæ•´")

    # è§£å¯† GitHub Token
    from ..utils.security import decrypt
    github_token = decrypt(current_user.githubToken)

    # è§£æä»“åº“ä¿¡æ¯
    repo_url = current_user.defaultRepoUrl
    if not repo_url.startswith('https://github.com/'):
        raise Exception("æ— æ•ˆçš„ GitHub ä»“åº“ URL")

    parts = repo_url.replace('https://github.com/', '').split('/')
    if len(parts) != 2:
        raise Exception("æ— æ•ˆçš„ GitHub ä»“åº“ URL æ ¼å¼")

    username, repo_name = parts

    # è¯»å–å›¾ç‰‡æ–‡ä»¶
    with open(image_path, 'rb') as f:
        image_data = f.read()

    # è½¬æ¢ä¸º base64
    image_base64 = base64.b64encode(image_data).decode('utf-8')

    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    import uuid
    from datetime import datetime
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    unique_id = str(uuid.uuid4())[:8]
    file_extension = image_path.suffix
    github_filename = f"imported_{timestamp}_{unique_id}{file_extension}"

    # GitHub æ–‡ä»¶è·¯å¾„
    file_path = f"assets/images/{github_filename}"

    # GitHub API URL
    api_url = f"https://api.github.com/repos/{username}/{repo_name}/contents/{file_path}"

    # å‡†å¤‡è¯·æ±‚æ•°æ®
    data = {
        "message": f"Import image: {github_filename}",
        "content": image_base64,
        "branch": "main"
    }

    headers = {
        "Authorization": f"token {github_token}",
        "Accept": "application/vnd.github.v3+json"
    }

    # å‘é€è¯·æ±‚
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.put(api_url, json=data, headers=headers)

        if response.status_code not in [201, 200]:
            logger.error(f"âŒ GitHub API error: {response.status_code} - {response.text}")
            raise Exception(f"GitHub ä¸Šä¼ å¤±è´¥: {response.status_code}")

        # ç”Ÿæˆå›¾ç‰‡çš„è®¿é—® URL
        image_url = f"https://raw.githubusercontent.com/{username}/{repo_name}/main/{file_path}"

        return image_url