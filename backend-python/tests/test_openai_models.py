#!/usr/bin/env python3
"""
æµ‹è¯•OpenAIç‰¹å®šæ¨¡å‹çš„è„šæœ¬
"""

import asyncio
import sys
from pathlib import Path
import openai

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from app.database import SessionLocal
from app.models import User
from app.utils.security import decrypt
from app.models_config import OPENAI_MODELS

async def test_openai_models():
    """æµ‹è¯•OpenAIæ¨¡å‹"""

    db = SessionLocal()

    try:
        # è·å–ç”¨æˆ·
        user = db.query(User).filter(User.id == "99946c0e-b6bd-457d-bfbd-d9d360ebf030").first()
        if not user or not user.openaiKey:
            print("âŒ ç”¨æˆ·ä¸å­˜åœ¨æˆ–æœªé…ç½®OpenAIå¯†é’¥")
            return

        # è§£å¯†APIå¯†é’¥
        api_key = decrypt(user.openaiKey)
        client = openai.OpenAI(api_key=api_key)

        print("=" * 60)
        print("ğŸ§ª æµ‹è¯•OpenAIæ¨¡å‹é…ç½®")
        print("=" * 60)

        # æ˜¾ç¤ºé…ç½®çš„æ¨¡å‹
        print("\nğŸ“‹ é…ç½®çš„OpenAIæ¨¡å‹ï¼š")
        for model_id, info in OPENAI_MODELS.items():
            print(f"  â€¢ {model_id}")
            print(f"    åç§°: {info['name']}")
            print(f"    æè¿°: {info['description']}")
            print()

        # æµ‹è¯•æ¯ä¸ªæ¨¡å‹
        test_models = [
            "gpt-5-2025-08-07",
            "gpt-5-mini-2025-08-07",
            "gpt-4.1-2025-04-14"
        ]

        print("=" * 60)
        print("ğŸ”„ å¼€å§‹æµ‹è¯•æ¨¡å‹æ¥å£...")
        print("=" * 60)

        for model_id in test_models:
            print(f"\nğŸ“ æµ‹è¯•æ¨¡å‹: {model_id}")
            print(f"   é…ç½®: {OPENAI_MODELS.get(model_id, {}).get('name', 'Unknown')}")

            try:
                # å°è¯•ç®€å•çš„APIè°ƒç”¨
                response = client.chat.completions.create(
                    model=model_id,
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant."},
                        {"role": "user", "content": "Say 'Model test successful' in 3 words."}
                    ],
                    max_tokens=20,
                    temperature=0
                )

                result = response.choices[0].message.content
                print(f"   âœ… æˆåŠŸ!")
                print(f"   å“åº”: {result}")

                # è·å–ä½¿ç”¨çš„tokenä¿¡æ¯
                if hasattr(response, 'usage'):
                    print(f"   Tokens: {response.usage.total_tokens}")

            except openai.NotFoundError as e:
                print(f"   âŒ æ¨¡å‹ä¸å­˜åœ¨: {str(e)[:100]}")
            except openai.BadRequestError as e:
                error_msg = str(e)
                if "max_tokens" in error_msg:
                    print(f"   âš ï¸  å‚æ•°é—®é¢˜ï¼Œå°è¯•ä¸å¸¦max_tokens...")
                    # é‡è¯•ä¸å¸¦max_tokens
                    try:
                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[
                                {"role": "system", "content": "You are a helpful assistant."},
                                {"role": "user", "content": "Say 'Model test successful' in 3 words."}
                            ],
                            temperature=0
                        )
                        result = response.choices[0].message.content
                        print(f"   âœ… æˆåŠŸ (æ— max_tokens)!")
                        print(f"   å“åº”: {result}")
                    except Exception as e2:
                        print(f"   âŒ ä»ç„¶å¤±è´¥: {str(e2)[:100]}")
                else:
                    print(f"   âŒ è¯·æ±‚é”™è¯¯: {error_msg[:100]}")
            except openai.RateLimitError as e:
                print(f"   âš ï¸  é€Ÿç‡é™åˆ¶: {str(e)[:100]}")
            except openai.AuthenticationError as e:
                print(f"   âŒ è®¤è¯å¤±è´¥: {str(e)[:100]}")
            except Exception as e:
                print(f"   âŒ æœªçŸ¥é”™è¯¯: {type(e).__name__}: {str(e)[:100]}")

        print("\n" + "=" * 60)

        # åˆ—å‡ºè´¦æˆ·å®é™…å¯ç”¨çš„æ¨¡å‹
        print("\nğŸ” æŸ¥è¯¢è´¦æˆ·å®é™…å¯ç”¨çš„æ¨¡å‹...")
        try:
            models = client.models.list()
            gpt_models = [m.id for m in models.data if 'gpt' in m.id.lower()]

            print(f"ğŸ“‹ è´¦æˆ·å¯ç”¨çš„GPTæ¨¡å‹ (å…±{len(gpt_models)}ä¸ª):")
            for model in sorted(gpt_models)[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"   â€¢ {model}")

            # æ£€æŸ¥æˆ‘ä»¬é…ç½®çš„æ¨¡å‹æ˜¯å¦åœ¨å¯ç”¨åˆ—è¡¨ä¸­
            print("\nğŸ” éªŒè¯é…ç½®çš„æ¨¡å‹æ˜¯å¦å¯ç”¨:")
            for model_id in test_models:
                if model_id in gpt_models:
                    print(f"   âœ… {model_id} - å¯ç”¨")
                else:
                    print(f"   âŒ {model_id} - ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­")

        except Exception as e:
            print(f"âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨: {e}")

        print("\n" + "=" * 60)
        print("âœ¨ OpenAIæ¨¡å‹æµ‹è¯•å®Œæˆ!")
        print("=" * 60)

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        db.close()

if __name__ == "__main__":
    print("\nğŸš€ OpenAIæ¨¡å‹éªŒè¯å·¥å…·\n")
    asyncio.run(test_openai_models())