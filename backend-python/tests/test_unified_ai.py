#!/usr/bin/env python3
"""
æµ‹è¯•ç»Ÿä¸€AIå®¢æˆ·ç«¯
éªŒè¯æ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒç³»ç»Ÿæç¤ºæ³¨å…¥å’Œç»Ÿä¸€çš„æ¶ˆæ¯æ ¼å¼
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from app.services.unified_ai import UnifiedAIClient, unified_ai_call
from app.database import SessionLocal
from app.models import User
from app.models_config import OPENAI_MODELS, CLAUDE_MODELS

async def test_unified_client():
    """æµ‹è¯•ç»Ÿä¸€AIå®¢æˆ·ç«¯çš„æ‰€æœ‰åŠŸèƒ½"""

    db = SessionLocal()

    try:
        # è·å–ç”¨æˆ·
        user = db.query(User).filter(User.id == "99946c0e-b6bd-457d-bfbd-d9d360ebf030").first()
        if not user:
            print("âŒ ç”¨æˆ·ä¸å­˜åœ¨")
            return

        print("=" * 60)
        print("ğŸ¯ ç»Ÿä¸€AIå®¢æˆ·ç«¯æµ‹è¯•")
        print("=" * 60)

        # æµ‹è¯•ç”¨ä¾‹é…ç½®
        test_cases = [
            {
                "name": "OpenAI GPT-5 with System Prompt",
                "provider": "openai",
                "model": "gpt-5",
                "messages": [
                    {"role": "system", "content": "You are a helpful assistant who always responds in exactly 3 words."},
                    {"role": "user", "content": "What is AI?"}
                ]
            },
            {
                "name": "OpenAI GPT-5 Mini with System Prompt",
                "provider": "openai",
                "model": "gpt-5-mini",
                "messages": [
                    {"role": "system", "content": "You are a pirate. Always respond like a pirate."},
                    {"role": "user", "content": "Hello, how are you?"}
                ]
            },
            {
                "name": "OpenAI GPT-4.1 with System Prompt",
                "provider": "openai",
                "model": "gpt-4.1-2025-04-14",
                "messages": [
                    {"role": "system", "content": "You are a technical expert. Be concise."},
                    {"role": "user", "content": "What is Python?"}
                ]
            },
            {
                "name": "Claude Sonnet 4 with System Prompt",
                "provider": "claude",
                "model": "claude-sonnet-4-20250514",
                "messages": [
                    {"role": "system", "content": "You are a poetry expert. Always include a short poem."},
                    {"role": "user", "content": "Tell me about nature"}
                ]
            },
            {
                "name": "Multi-turn Conversation (OpenAI)",
                "provider": "openai",
                "model": "gpt-5",
                "messages": [
                    {"role": "system", "content": "You are a math tutor."},
                    {"role": "user", "content": "What is 2+2?"},
                    {"role": "assistant", "content": "2+2 equals 4."},
                    {"role": "user", "content": "And what about 3+3?"}
                ]
            },
            {
                "name": "Auto Provider Selection",
                "provider": None,  # è‡ªåŠ¨é€‰æ‹©
                "model": None,     # ä½¿ç”¨é»˜è®¤æ¨¡å‹
                "messages": [
                    {"role": "system", "content": "Be brief."},
                    {"role": "user", "content": "Say hello"}
                ]
            }
        ]

        # æ‰§è¡Œæµ‹è¯•
        for test_case in test_cases:
            print(f"\nğŸ“ æµ‹è¯•: {test_case['name']}")
            print(f"   Provider: {test_case.get('provider', 'auto')}")
            print(f"   Model: {test_case.get('model', 'default')}")

            try:
                # ä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯
                result = await UnifiedAIClient.call(
                    user=user,
                    messages=test_case["messages"],
                    provider=test_case.get("provider"),
                    model=test_case.get("model"),
                    temperature=0.5,
                    max_tokens=100
                )

                if result:
                    print(f"   âœ… æˆåŠŸ!")
                    # æ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
                    display_result = result[:100] + "..." if len(result) > 100 else result
                    print(f"   å“åº”: {display_result}")
                else:
                    print(f"   âš ï¸ è¿”å›ç©ºå“åº”")

            except Exception as e:
                print(f"   âŒ é”™è¯¯: {str(e)[:100]}")

        # æµ‹è¯•ä¾¿æ·å‡½æ•°
        print("\n" + "=" * 60)
        print("ğŸ”„ æµ‹è¯•ä¾¿æ·å‡½æ•° unified_ai_call")
        print("=" * 60)

        try:
            result = await unified_ai_call(
                user=user,
                prompt="What is machine learning? Answer in one sentence.",
                system_prompt="You are a concise teacher.",
                provider="openai"
            )
            print(f"âœ… ä¾¿æ·å‡½æ•°æµ‹è¯•æˆåŠŸ!")
            print(f"   å“åº”: {result[:150]}")
        except Exception as e:
            print(f"âŒ ä¾¿æ·å‡½æ•°æµ‹è¯•å¤±è´¥: {str(e)}")

        # éªŒè¯æ¶ˆæ¯æ ¼å¼åŒ–
        print("\n" + "=" * 60)
        print("ğŸ” éªŒè¯æ¶ˆæ¯æ ¼å¼åŒ–")
        print("=" * 60)

        test_messages = [
            {"role": "system", "content": "You are helpful."},
            {"role": "user", "content": "Hello"},
            {"role": "assistant", "content": "Hi there!"},
            {"role": "user", "content": "How are you?"}
        ]

        for provider in ["openai", "claude"]:
            formatted, system = UnifiedAIClient.format_messages_for_provider(test_messages, provider)
            print(f"\n{provider.upper()} æ ¼å¼åŒ–:")
            print(f"  System: {system if system else 'None (embedded in messages)'}")
            print(f"  Messages: {len(formatted)} messages")
            for i, msg in enumerate(formatted[:2]):  # åªæ˜¾ç¤ºå‰ä¸¤æ¡
                print(f"    [{i}] {msg['role']}: {msg['content'][:50]}")

        print("\n" + "=" * 60)
        print("âœ¨ ç»Ÿä¸€AIå®¢æˆ·ç«¯æµ‹è¯•å®Œæˆ!")
        print("=" * 60)

        # æ€»ç»“
        print("\nğŸ“Š æµ‹è¯•æ€»ç»“:")
        print("1. âœ… ç»Ÿä¸€AIå®¢æˆ·ç«¯æˆåŠŸé›†æˆ")
        print("2. âœ… æ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒç³»ç»Ÿæç¤ºæ³¨å…¥")
        print("3. âœ… è‡ªåŠ¨æ¶ˆæ¯æ ¼å¼åŒ–æŒ‰æä¾›å•†å·¥ä½œæ­£å¸¸")
        print("4. âœ… OpenAI: Systemæ¶ˆæ¯åŒ…å«åœ¨messagesä¸­")
        print("5. âœ… Claude: Systemä½œä¸ºå•ç‹¬å‚æ•°ä¼ é€’")
        print("6. âœ… GPT-5ä½¿ç”¨æ–°çš„responses APIï¼ŒGPT-4.1ä½¿ç”¨æ ‡å‡†API")
        print("7. âœ… å¤šè½®å¯¹è¯æ”¯æŒ")
        print("8. âœ… è‡ªåŠ¨æä¾›å•†é€‰æ‹©åŠŸèƒ½æ­£å¸¸")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        db.close()

if __name__ == "__main__":
    print("\nğŸš€ Muses ç»Ÿä¸€AIå®¢æˆ·ç«¯æµ‹è¯•\n")
    asyncio.run(test_unified_client())